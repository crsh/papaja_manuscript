@Book{american_psychological_association_publication_2010,
  location = {{Washington, DC}},
  edition = {6th edition},
  title = {Publication {{Manual}} of the {{American Psychological Association}}},
  abstract = {The {"}Publication Manual{"} is the style manual of choice for writers, editors, students, and educators. Although it is specifically designed to help writers in the behavioral sciences and social sciences, anyone who writes non-fiction prose can benefit from its guidance. The newly-revised Sixth Edition has not only been rewritten. It has also been thoroughly rethought and reorganized, making it the most user-friendly {"}Publication Manual{"} the APA has ever produced. You will be able to find answers to your questions faster than ever before. When you need advice on how to present information, including text, data, and graphics, for publication in any type of format--such as college and university papers, professional journals, presentations for colleagues, and online publication--you will find the advice you're looking for in the {"}Publication Manual.{"}},
  pagetotal = {272},
  timestamp = {2015-05-28T15:11:27Z},
  langid = {english},
  publisher = {{American Psychological Association}},
  author = {{American Psychological Association}},
  date = {2010},
}
@Article{patil_statistical_2016,
  title = {A Statistical Definition for Reproducibility and Replicability},
  rights = {© 2016, Published by Cold Spring Harbor Laboratory Press. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  url = {http://biorxiv.org/content/early/2016/07/29/066803},
  doi = {10.1101/066803},
  abstract = {Everyone agrees that reproducibility and replicability are fundamental characteristics of scientific studies. These topics are attracting increasing attention, scrutiny, and debate both in the popular press and the scientific literature. But there are no formal statistical definitions for these concepts, which leads to confusion since the same words are used for different concepts by different people in different fields. We provide formal and informal definitions of scientific studies, reproducibility, and replicability that can be used to clarify discussions around these concepts in the scientific and popular press.},
  timestamp = {2016-09-25T18:54:40Z},
  langid = {english},
  journaltitle = {bioRxiv},
  author = {Prasad Patil and Roger D. Peng and Jeffrey Leek},
  urldate = {2016-09-25},
  date = {2016-07-29},
  pages = {066803},
  file = {Full Text PDF:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/KE7PHNI8/Patil et al. - 2016 - A statistical definition for reproducibility and r.pdf:application/pdf},
}
@Article{asendorpf_recommendations_2013,
  title = {Recommendations for {{Increasing Replicability}} in {{Psychology}}},
  volume = {27},
  issn = {1099-0984},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/per.1919/abstract},
  doi = {10.1002/per.1919},
  abstract = {Replicability of findings is at the heart of any empirical science. The aim of this article is to move the current replicability debate in psychology towards concrete recommendations for improvement. We focus on research practices but also offer guidelines for reviewers, editors, journal management, teachers, granting institutions, and university promotion committees, highlighting some of the emerging and existing practical solutions that can facilitate implementation of these recommendations. The challenges for improving replicability in psychological science are systemic. Improvement can occur only if changes are made at many levels of practice, evaluation, and reward. Copyright © 2013 John Wiley \& Sons, Ltd.},
  timestamp = {2016-09-25T19:40:32Z},
  langid = {english},
  number = {2},
  journaltitle = {European Journal of Personality},
  shortjournal = {Eur. J. Pers.},
  author = {Jens B. Asendorpf and Mark Conner and Filip {De Fruyt} and Jan {De Houwer} and Jaap J. A. Denissen and Klaus Fiedler and Susann Fiedler and David C. Funder and Reinhold Kliegl and Brian A. Nosek and Marco Perugini and Brent W. Roberts and Manfred Schmitt and Marcel A. G. {van Aken} and Hannelore Weber and Jelte M. Wicherts},
  urldate = {2016-09-25},
  date = {2013-03-01},
  pages = {108--119},
  keywords = {confirmation bias,generalizability,publication bias,replicability,research transparency},
  options = {useprefix=true},
  file = {Full Text PDF:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/WP2KB228/Asendorpf et al. - 2013 - Recommendations for Increasing Replicability in Ps.pdf:application/pdf},
}

@Report{cacioppo_social_2015,
  location = {{Arlington, VA}},
  title = {Social, {{Behavioral}}, and {{Economic Sciences Perspectives}} on {{Robust}} and {{Reliable Science}}},
  url = {http://web.stanford.edu/group/bps/cgi-bin/wordpress/wp-content/uploads/2015/09/NSF-Robust-Research-Workshop-Report.pdf},
  timestamp = {2016-09-25T19:52:32Z},
  institution = {{National Science Foundation}},
  type = {Report of the {{Subcommittee}} on {{Replicability}} in {{Science}}},
  author = {John T. Cacioppo and Robert M. Kaplan and Jon A. Krosnick and James L. Olds and Heather Dean},
  urldate = {2016-09-25},
  date = {2015},
  file = {SBE_Robust_and_Reliable_Research_Report.pdf:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/THRZE8PX/SBE_Robust_and_Reliable_Research_Report.pdf:application/pdf},
}
@Book{gandrud_reproducible_2013,
  location = {{Boca Raton}},
  edition = {Auflage: New.},
  title = {Reproducible Research with R and Rstudio},
  isbn = {978-1-4665-7284-3},
  abstract = {Bringing together computational research tools in one accessible source, Reproducible Research with R and RStudio guides you in creating dynamic and highly reproducible research. Suitable for researchers in any quantitative empirical discipline, it presents practical tools for data collection, data analysis, and the presentation of results. With straightforward examples, the book takes you through a reproducible research workflow, showing you how to use: * R for dynamic data gathering and automated results presentation * knitr for combining statistical analysis and results into one document * LaTeX for creating PDF articles and slide shows, and Markdown and HTML for presenting results on the web * Cloud storage and versioning services that can store data, code, and presentation files; save previous versions of the files; and make the information widely available * Unix-like shell programs for compiling large projects and converting documents from one markup language to another * RStudio to tightly integrate reproducible research tools in one place Whether you're an advanced user or just getting started with tools such as R and LaTeX, this book saves you time searching for information and helps you successfully carry out computational research. It provides a practical reproducible research workflow that you can use to gather and analyze data as well as dynamically present results in print and on the web. Supplementary files used for the examples and a reproducible research project are available on the author's website.},
  pagetotal = {294},
  timestamp = {2015-03-10T00:27:26Z},
  langid = {Englisch},
  publisher = {{Crc Pr Inc}},
  author = {Christopher Gandrud},
  date = {2013-08-21},
  file = {reproducible-research-with-r-and-studio-2nd-edition.pdf:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/SPV8KZZS/reproducible-research-with-r-and-studio-2nd-edition.pdf:application/pdf},
}
@Book{stodden_implementing_2014,
  location = {{Boca Raton}},
  title = {Implementing {{Reproducible Research}}},
  isbn = {978-1-4665-6159-5},
  url = {https://osf.io/s9tya/},
  abstract = {In computational science, reproducibility requires that researchers make code and data available to others so that the data can be analyzed in a similar manner as in the original publication. Code must be available to be distributed, data must be accessible in a readable format, and a platform must be available for widely distributing the data and code. In addition, both data and code need to be licensed permissively enough so that others can reproduce the work without a substantial legal burden. Implementing Reproducible Research covers many of the elements necessary for conducting and distributing reproducible research. It explains how to accurately reproduce a scientific result.   Divided into three parts, the book discusses the tools, practices, and dissemination platforms for ensuring reproducibility in computational science. It describes:   Computational tools, such as Sweave, knitr, VisTrails, Sumatra, CDE, and the Declaratron system Open source practices, good programming practices, trends in open science, and the role of cloud computing in reproducible research Software and methodological platforms, including open source software packages, RunMyCode platform, and open access journals  Each part presents contributions from leaders who have developed software and other products that have advanced the field. Supplementary material is available at www.ImplementingRR.org.},
  pagetotal = {448},
  timestamp = {2016-09-25T20:18:29Z},
  langid = {english},
  publisher = {{Chapman and Hall/CRC}},
  author = {Victoria Stodden and Friedrich Leisch and Roger D. Peng},
  date = {2014-04-14},
}
@Article{pfister_schorsch:_2016,
  title = {{{schoRsch}}: {{An R}} Package for Analyzing and Reporting Factorial Experiments},
  volume = {12},
  issn = {2292-1354},
  url = {http://www.tqmp.org/RegularArticles/vol12-2/p147},
  doi = {10.20982/tqmp.12.2.p147},
  shorttitle = {{{schoRsch}}},
  timestamp = {2016-09-26T07:00:03Z},
  number = {2},
  journaltitle = {The Quantitative Methods for Psychology},
  author = {Roland Pfister and Markus Janczyk},
  urldate = {2016-09-26},
  date = {2016-09-01},
  pages = {147--151},
  file = {p147.pdf:/Users/frederikaust/Library/Application Support/Zotero/Profiles/dydhj5nr.default/zotero/storage/VN3TJBSD/p147.pdf:application/pdf},
}
@Article{cook_psychological_2006,
	title = {The psychological and social characteristics of patients referred for {NHS} cosmetic surgery: Quantifying clinical need},
	volume = {59},
	issn = {1748-6815},
	url = {http://www.sciencedirect.com/science/article/pii/S0007122605002894},
	doi = {10.1016/j.bjps.2005.08.004},
	shorttitle = {The psychological and social characteristics of patients referred for {NHS} cosmetic surgery},
	pages = {54--64},
	number = {1},
	journaltitle = {Journal of Plastic, Reconstructive \& Aesthetic Surgery},
	shortjournal = {Journal of Plastic, Reconstructive \& Aesthetic Surgery},
	author = {Cook, Sharon A. and Rosser, Robert and Toone, Helen and Ian James, M. and Salmon, Peter},
	urldate = {2017-11-18},
	date = {2006-01-01},
	keywords = {Abnormality, Clinical need, Cosmetic surgery, Psychosocial dysfunction},
	file = {ScienceDirect Full Text PDF:/home/mariusbarth/Zotero/storage/GZEJSH6B/Cook et al. - 2006 - The psychological and social characteristics of pa.pdf:application/pdf}
}

@book {james_1890,
  Title = {The principles of psychology},
  Author = {James, William},
  Year = {1890},
  address = {Holt: New York}
}

@article {bem_2011,
  Title = {Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect},
  Author = {Bem, Daryl J},
  DOI = {10.1037/a0021524},
  Number = {3},
  Volume = {100},
  Month = {March},
  Year = {2011},
  Journal = {Journal of personality and social psychology},
  ISSN = {0022-3514},
  Pages = {407—425},
  URL = {http://dx.doi.org/10.1037/a0021524},
}
@Article{NosofskyActivationneuralnetwork2012a,
  langid = {english},
  title = {Activation in the Neural Network Responsible for Categorization and Recognition Reflects Parameter Changes},
  volume = {109},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/content/109/1/333},
  doi = {10.1073/pnas.1111304109},
  abstract = {According to various influential formal models of cognition, perceptual categorization and old−new recognition recruit the same memory system. By contrast, the prevailing view in the cognitive neuroscience literature is that separate neural systems mediate perceptual categorization and recognition. A direct form of evidence is that separate brain regions are activated when observers engage in categorization and recognition tasks involving the same types of stimuli. However, even if the same memory-based comparison processes underlie categorization and recognition, one would not expect to see identical patterns of brain activity across the tasks; the reason is that observers would adjust parameter settings (e.g., vary criterion settings) across the tasks to satisfy the different task goals. In this fMRI study, we conducted categorization and recognition tasks in which stimulus conditions were held constant, and in which observers were induced to vary hypothesized parameter settings across conditions. A formal exemplar model was fitted to the data to track the changes in parameters to help interpret the fMRI results. We observed systematic effects of changes in parameters on patterns of brain activity, which were interpretable in terms of differing forms of evidence accumulation that resulted from the changed parameter settings. After controlling for stimulus and parameter-related differences, we found little evidence that categorization and recognition recruit separate memory systems.},
  number = {1},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  author = {Robert M. Nosofsky and Daniel R. Little and Thomas W. James},
  urldate = {2014-01-21},
  date = {2012-03-01},
  pages = {333--338},
  note = {00021 PMID: 22184233},
  file = {/Users/frederikaust/Zotero/storage/763GRVWX/Nosofsky_et_al_2012_Activation_in_the_neural_network_responsible_for_categorization_and_recognition.pdf},
}

@Article{NosofskyActivationneuralnetwork2012,
  langid = {english},
  title = {Activation in the Neural Network Responsible for Categorization and Recognition Reflects Parameter Changes},
  volume = {109},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org/content/109/1/333},
  doi = {10.1073/pnas.1111304109},
  abstract = {According to various influential formal models of cognition, perceptual categorization and old−new recognition recruit the same memory system. By contrast, the prevailing view in the cognitive neuroscience literature is that separate neural systems mediate perceptual categorization and recognition. A direct form of evidence is that separate brain regions are activated when observers engage in categorization and recognition tasks involving the same types of stimuli. However, even if the same memory-based comparison processes underlie categorization and recognition, one would not expect to see identical patterns of brain activity across the tasks; the reason is that observers would adjust parameter settings (e.g., vary criterion settings) across the tasks to satisfy the different task goals. In this fMRI study, we conducted categorization and recognition tasks in which stimulus conditions were held constant, and in which observers were induced to vary hypothesized parameter settings across conditions. A formal exemplar model was fitted to the data to track the changes in parameters to help interpret the fMRI results. We observed systematic effects of changes in parameters on patterns of brain activity, which were interpretable in terms of differing forms of evidence accumulation that resulted from the changed parameter settings. After controlling for stimulus and parameter-related differences, we found little evidence that categorization and recognition recruit separate memory systems.},
  number = {1},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  author = {Robert M. Nosofsky and Daniel R. Little and Thomas W. James},
  urldate = {2015-05-16},
  date = {2012-03-01},
  pages = {333--338},
  file = {/Users/frederikaust/Zotero/storage/H7S6T4N4/Nosofsky et al. - 2012 - Activation in the neural network responsible for c.pdf},
  eprinttype = {pmid},
  eprint = {22184233},
}

@Book{JamesPrinciplesPsychologyVol1950,
  langid = {english},
  location = {{New York}},
  edition = {Reprint edition},
  title = {The {{Principles}} of {{Psychology}}, {{Vol}}. 1},
  isbn = {978-0-486-20381-2},
  abstract = {Volume 1 of the famous long course, complete and unabridged. Stream of thought, time perception, memory, experimental methods — these are only some of the concerns of a work that was years ahead of its time and is still valid, interesting and useful. Total in set: 94 figures.},
  pagetotal = {696},
  publisher = {{Dover Publications}},
  author = {William James},
  date = {1950-06-01},
  note = {00008},
}
@Article{CummingReplicationIntervalsValues2008,
  langid = {english},
  title = {Replication and p {{Intervals}}: P {{Values Predict}} the {{Future Only Vaguely}}, but {{Confidence Intervals Do Much Better}}},
  volume = {3},
  issn = {1745-6916, 1745-6924},
  url = {http://pps.sagepub.com/content/3/4/286},
  doi = {10.1111/j.1745-6924.2008.00079.x},
  shorttitle = {Replication and p {{Intervals}}},
  abstract = {Replication is fundamental to science, so statistical analysis should give information about replication. Because p values dominate statistical analysis in psychology, it is important to ask what p says about replication. The answer to this question is “Surprisingly little.” In one simulation of 25 repetitions of a typical experiment, p varied from $<$.001 to .76, thus illustrating that p is a very unreliable measure. This article shows that, if an initial experiment results in two-tailed p = .05, there is an 80\% chance the one-tailed p value from a replication will fall in the interval (.00008, .44), a 10\% chance that p $<$.00008, and fully a 10\% chance that p $>$.44. Remarkably, the interval—termed a p interval—is this wide however large the sample size. p is so unreliable and gives such dramatically vague information that it is a poor basis for inference. Confidence intervals, however, give much better information about replication. Researchers should minimize the role of p by using confidence intervals and model-fitting techniques and by adopting meta-analytic thinking.},
  number = {4},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspectives on Psychological Science},
  author = {Geoff Cumming},
  urldate = {2015-03-23},
  date = {2008-07-01},
  pages = {286--300},
  note = {00000},
  file = {/Users/frederikaust/Zotero/storage/23I3ZUTJ/Cumming - 2008 - Replication and p Intervals p Values Predict the .pdf},
}
